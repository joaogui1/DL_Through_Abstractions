{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Test_aula5.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "nyVm1KUeJRYE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "import keras\n",
        "from keras.utils import to_categorical\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "m26TiWqXJxRN",
        "colab_type": "code",
        "outputId": "673667df-3e3b-4eca-c1df-c9519fdaf155",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "cell_type": "code",
      "source": [
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7GP3jTAdKFe0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_train = X_train.astype(np.float32)/255.0\n",
        "X_test = X_test.astype(np.float32)/255.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FrfDvrlmKUqE",
        "colab_type": "code",
        "outputId": "95895da9-960e-4d98-9593-216d4b319e2f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "X_train = X_train.reshape(60000, 784)\n",
        "X_test = X_test.reshape(10000, 784)\n",
        "X_train.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 784)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "metadata": {
        "id": "8zd8pI5OM1Pg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_test = to_categorical(y_test)\n",
        "y_train = to_categorical(y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mWXjxKJqKdh1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "naive_mlp = Sequential()\n",
        "naive_mlp.add(Dense(units=64, activation='relu', input_shape=(784,)))\n",
        "naive_mlp.add(Dense(units=32, activation='relu'))\n",
        "naive_mlp.add(Dense(units=10, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sD_zupmqLJiV",
        "colab_type": "code",
        "outputId": "022d7742-491e-4fa3-9503-67e9e745efb4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 413
        }
      },
      "cell_type": "code",
      "source": [
        "naive_mlp.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "naive_mlp.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=32)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 10s 174us/step - loss: 0.6972 - acc: 0.8059 - val_loss: 0.3407 - val_acc: 0.9026\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 10s 166us/step - loss: 0.3155 - acc: 0.9091 - val_loss: 0.2727 - val_acc: 0.9245\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 10s 173us/step - loss: 0.2611 - acc: 0.9250 - val_loss: 0.2356 - val_acc: 0.9322\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 10s 172us/step - loss: 0.2272 - acc: 0.9347 - val_loss: 0.2115 - val_acc: 0.9388\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 10s 170us/step - loss: 0.2016 - acc: 0.9420 - val_loss: 0.1958 - val_acc: 0.9424\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 10s 169us/step - loss: 0.1817 - acc: 0.9484 - val_loss: 0.1771 - val_acc: 0.9476\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 10s 163us/step - loss: 0.1656 - acc: 0.9519 - val_loss: 0.1634 - val_acc: 0.9519\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 10s 163us/step - loss: 0.1517 - acc: 0.9563 - val_loss: 0.1555 - val_acc: 0.9557\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 10s 166us/step - loss: 0.1408 - acc: 0.9597 - val_loss: 0.1461 - val_acc: 0.9580\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 10s 169us/step - loss: 0.1310 - acc: 0.9622 - val_loss: 0.1386 - val_acc: 0.9589\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fd0100824a8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "metadata": {
        "id": "9vj6Bus9Lt_q",
        "colab_type": "code",
        "outputId": "8888dddd-8f9c-45f1-900b-4fdafdb6b238",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1133
        }
      },
      "cell_type": "code",
      "source": [
        "naive_mlp.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "naive_mlp.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=30, batch_size=32)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/30\n",
            "60000/60000 [==============================] - 13s 225us/step - loss: 0.3011 - acc: 0.9126 - val_loss: 0.1642 - val_acc: 0.9519\n",
            "Epoch 2/30\n",
            "60000/60000 [==============================] - 12s 207us/step - loss: 0.1360 - acc: 0.9600 - val_loss: 0.1236 - val_acc: 0.9621\n",
            "Epoch 3/30\n",
            "60000/60000 [==============================] - 12s 207us/step - loss: 0.1013 - acc: 0.9688 - val_loss: 0.1195 - val_acc: 0.9661\n",
            "Epoch 4/30\n",
            "60000/60000 [==============================] - 13s 209us/step - loss: 0.0781 - acc: 0.9764 - val_loss: 0.1056 - val_acc: 0.9694\n",
            "Epoch 5/30\n",
            "60000/60000 [==============================] - 13s 209us/step - loss: 0.0654 - acc: 0.9790 - val_loss: 0.0940 - val_acc: 0.9706\n",
            "Epoch 6/30\n",
            "60000/60000 [==============================] - 13s 209us/step - loss: 0.0553 - acc: 0.9829 - val_loss: 0.1123 - val_acc: 0.9667\n",
            "Epoch 7/30\n",
            "60000/60000 [==============================] - 13s 218us/step - loss: 0.0474 - acc: 0.9845 - val_loss: 0.0892 - val_acc: 0.9764\n",
            "Epoch 8/30\n",
            "60000/60000 [==============================] - 12s 203us/step - loss: 0.0405 - acc: 0.9869 - val_loss: 0.0977 - val_acc: 0.9730\n",
            "Epoch 9/30\n",
            "60000/60000 [==============================] - 12s 195us/step - loss: 0.0365 - acc: 0.9885 - val_loss: 0.0957 - val_acc: 0.9743\n",
            "Epoch 10/30\n",
            "60000/60000 [==============================] - 12s 193us/step - loss: 0.0306 - acc: 0.9903 - val_loss: 0.1014 - val_acc: 0.9731\n",
            "Epoch 11/30\n",
            "60000/60000 [==============================] - 13s 212us/step - loss: 0.0279 - acc: 0.9909 - val_loss: 0.1078 - val_acc: 0.9731\n",
            "Epoch 12/30\n",
            "60000/60000 [==============================] - 12s 207us/step - loss: 0.0255 - acc: 0.9913 - val_loss: 0.1095 - val_acc: 0.9735\n",
            "Epoch 13/30\n",
            "60000/60000 [==============================] - 12s 204us/step - loss: 0.0236 - acc: 0.9922 - val_loss: 0.1146 - val_acc: 0.9740\n",
            "Epoch 14/30\n",
            "60000/60000 [==============================] - 12s 206us/step - loss: 0.0208 - acc: 0.9932 - val_loss: 0.1122 - val_acc: 0.9748\n",
            "Epoch 15/30\n",
            "60000/60000 [==============================] - 13s 212us/step - loss: 0.0198 - acc: 0.9933 - val_loss: 0.1192 - val_acc: 0.9737\n",
            "Epoch 16/30\n",
            "60000/60000 [==============================] - 12s 203us/step - loss: 0.0166 - acc: 0.9945 - val_loss: 0.1343 - val_acc: 0.9729\n",
            "Epoch 17/30\n",
            "60000/60000 [==============================] - 12s 203us/step - loss: 0.0168 - acc: 0.9940 - val_loss: 0.1152 - val_acc: 0.9752\n",
            "Epoch 18/30\n",
            "60000/60000 [==============================] - 12s 202us/step - loss: 0.0155 - acc: 0.9949 - val_loss: 0.1204 - val_acc: 0.9747\n",
            "Epoch 19/30\n",
            "60000/60000 [==============================] - 12s 206us/step - loss: 0.0148 - acc: 0.9951 - val_loss: 0.1366 - val_acc: 0.9734\n",
            "Epoch 20/30\n",
            "60000/60000 [==============================] - 12s 207us/step - loss: 0.0150 - acc: 0.9950 - val_loss: 0.1410 - val_acc: 0.9730\n",
            "Epoch 21/30\n",
            "60000/60000 [==============================] - 12s 205us/step - loss: 0.0133 - acc: 0.9955 - val_loss: 0.1310 - val_acc: 0.9747\n",
            "Epoch 22/30\n",
            "60000/60000 [==============================] - 12s 203us/step - loss: 0.0126 - acc: 0.9956 - val_loss: 0.1384 - val_acc: 0.9735\n",
            "Epoch 23/30\n",
            "60000/60000 [==============================] - 12s 207us/step - loss: 0.0129 - acc: 0.9959 - val_loss: 0.1322 - val_acc: 0.9736\n",
            "Epoch 24/30\n",
            "60000/60000 [==============================] - 12s 206us/step - loss: 0.0118 - acc: 0.9960 - val_loss: 0.1547 - val_acc: 0.9724\n",
            "Epoch 25/30\n",
            "60000/60000 [==============================] - 12s 201us/step - loss: 0.0120 - acc: 0.9961 - val_loss: 0.1518 - val_acc: 0.9718\n",
            "Epoch 26/30\n",
            "60000/60000 [==============================] - 13s 212us/step - loss: 0.0125 - acc: 0.9959 - val_loss: 0.1484 - val_acc: 0.9740\n",
            "Epoch 27/30\n",
            "60000/60000 [==============================] - 12s 203us/step - loss: 0.0104 - acc: 0.9968 - val_loss: 0.1368 - val_acc: 0.9755\n",
            "Epoch 28/30\n",
            "60000/60000 [==============================] - 12s 202us/step - loss: 0.0105 - acc: 0.9967 - val_loss: 0.1437 - val_acc: 0.9762\n",
            "Epoch 29/30\n",
            "60000/60000 [==============================] - 13s 213us/step - loss: 0.0103 - acc: 0.9967 - val_loss: 0.1602 - val_acc: 0.9743\n",
            "Epoch 30/30\n",
            "60000/60000 [==============================] - 13s 215us/step - loss: 0.0092 - acc: 0.9969 - val_loss: 0.1524 - val_acc: 0.9752\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fcffc0cb550>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "metadata": {
        "id": "toBrUlhKQNDF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "dropout_mlp = Sequential()\n",
        "dropout_mlp.add(Dense(units=64, activation='relu', input_shape=(784,)))\n",
        "dropout_mlp.add(Dropout(0.2))\n",
        "dropout_mlp.add(Dense(units=32, activation='relu'))\n",
        "dropout_mlp.add(Dropout(0.3))\n",
        "dropout_mlp.add(Dense(units=10, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "urbwyUWCQ-45",
        "colab_type": "code",
        "outputId": "d24e2aa8-07b1-4ee6-b3e6-7aed18ade577",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1133
        }
      },
      "cell_type": "code",
      "source": [
        "dropout_mlp.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "dropout_mlp.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=30, batch_size=32)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/30\n",
            "60000/60000 [==============================] - 14s 236us/step - loss: 0.5010 - acc: 0.8482 - val_loss: 0.1846 - val_acc: 0.9467\n",
            "Epoch 2/30\n",
            "60000/60000 [==============================] - 14s 238us/step - loss: 0.2634 - acc: 0.9242 - val_loss: 0.1426 - val_acc: 0.9573\n",
            "Epoch 3/30\n",
            "60000/60000 [==============================] - 13s 223us/step - loss: 0.2156 - acc: 0.9388 - val_loss: 0.1298 - val_acc: 0.9621\n",
            "Epoch 4/30\n",
            "60000/60000 [==============================] - 13s 223us/step - loss: 0.1913 - acc: 0.9453 - val_loss: 0.1227 - val_acc: 0.9636\n",
            "Epoch 5/30\n",
            "60000/60000 [==============================] - 13s 221us/step - loss: 0.1747 - acc: 0.9500 - val_loss: 0.1072 - val_acc: 0.9674\n",
            "Epoch 6/30\n",
            "60000/60000 [==============================] - 13s 221us/step - loss: 0.1637 - acc: 0.9532 - val_loss: 0.1047 - val_acc: 0.9684\n",
            "Epoch 7/30\n",
            "60000/60000 [==============================] - 13s 219us/step - loss: 0.1520 - acc: 0.9558 - val_loss: 0.1055 - val_acc: 0.9690\n",
            "Epoch 8/30\n",
            "60000/60000 [==============================] - 14s 226us/step - loss: 0.1457 - acc: 0.9574 - val_loss: 0.1054 - val_acc: 0.9696\n",
            "Epoch 9/30\n",
            "60000/60000 [==============================] - 14s 228us/step - loss: 0.1398 - acc: 0.9585 - val_loss: 0.1139 - val_acc: 0.9702\n",
            "Epoch 10/30\n",
            "60000/60000 [==============================] - 13s 219us/step - loss: 0.1355 - acc: 0.9604 - val_loss: 0.1052 - val_acc: 0.9709\n",
            "Epoch 11/30\n",
            "60000/60000 [==============================] - 13s 220us/step - loss: 0.1302 - acc: 0.9615 - val_loss: 0.1071 - val_acc: 0.9697\n",
            "Epoch 12/30\n",
            "60000/60000 [==============================] - 13s 215us/step - loss: 0.1248 - acc: 0.9638 - val_loss: 0.1030 - val_acc: 0.9708\n",
            "Epoch 13/30\n",
            "60000/60000 [==============================] - 13s 223us/step - loss: 0.1246 - acc: 0.9629 - val_loss: 0.1033 - val_acc: 0.9715\n",
            "Epoch 14/30\n",
            "60000/60000 [==============================] - 13s 221us/step - loss: 0.1174 - acc: 0.9654 - val_loss: 0.1042 - val_acc: 0.9706\n",
            "Epoch 15/30\n",
            "60000/60000 [==============================] - 14s 229us/step - loss: 0.1178 - acc: 0.9654 - val_loss: 0.1058 - val_acc: 0.9700\n",
            "Epoch 16/30\n",
            "60000/60000 [==============================] - 14s 229us/step - loss: 0.1138 - acc: 0.9659 - val_loss: 0.1003 - val_acc: 0.9735\n",
            "Epoch 17/30\n",
            "60000/60000 [==============================] - 14s 228us/step - loss: 0.1110 - acc: 0.9666 - val_loss: 0.1017 - val_acc: 0.9728\n",
            "Epoch 18/30\n",
            "60000/60000 [==============================] - 13s 224us/step - loss: 0.1109 - acc: 0.9665 - val_loss: 0.1025 - val_acc: 0.9729\n",
            "Epoch 19/30\n",
            "60000/60000 [==============================] - 13s 225us/step - loss: 0.1071 - acc: 0.9677 - val_loss: 0.1099 - val_acc: 0.9718\n",
            "Epoch 20/30\n",
            "60000/60000 [==============================] - 14s 229us/step - loss: 0.1070 - acc: 0.9679 - val_loss: 0.1011 - val_acc: 0.9717\n",
            "Epoch 21/30\n",
            "60000/60000 [==============================] - 14s 231us/step - loss: 0.1021 - acc: 0.9698 - val_loss: 0.1033 - val_acc: 0.9743\n",
            "Epoch 22/30\n",
            "60000/60000 [==============================] - 14s 226us/step - loss: 0.1029 - acc: 0.9692 - val_loss: 0.1013 - val_acc: 0.9740\n",
            "Epoch 23/30\n",
            "60000/60000 [==============================] - 13s 219us/step - loss: 0.0999 - acc: 0.9697 - val_loss: 0.0964 - val_acc: 0.9740\n",
            "Epoch 24/30\n",
            "60000/60000 [==============================] - 13s 219us/step - loss: 0.0952 - acc: 0.9715 - val_loss: 0.1016 - val_acc: 0.9736\n",
            "Epoch 25/30\n",
            "60000/60000 [==============================] - 14s 234us/step - loss: 0.0974 - acc: 0.9708 - val_loss: 0.0991 - val_acc: 0.9752\n",
            "Epoch 26/30\n",
            "60000/60000 [==============================] - 13s 224us/step - loss: 0.0951 - acc: 0.9713 - val_loss: 0.1096 - val_acc: 0.9726\n",
            "Epoch 27/30\n",
            "60000/60000 [==============================] - 14s 227us/step - loss: 0.0972 - acc: 0.9703 - val_loss: 0.1035 - val_acc: 0.9736\n",
            "Epoch 28/30\n",
            "60000/60000 [==============================] - 14s 225us/step - loss: 0.0930 - acc: 0.9719 - val_loss: 0.1055 - val_acc: 0.9735\n",
            "Epoch 29/30\n",
            "60000/60000 [==============================] - 13s 220us/step - loss: 0.0939 - acc: 0.9710 - val_loss: 0.1046 - val_acc: 0.9744\n",
            "Epoch 30/30\n",
            "60000/60000 [==============================] - 14s 229us/step - loss: 0.0910 - acc: 0.9715 - val_loss: 0.1037 - val_acc: 0.9751\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fcffbc463c8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "metadata": {
        "id": "MNHXdnmHZZ4h",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.callbacks import *\n",
        "from keras.layers import Conv2D, Flatten, MaxPooling2D\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
        "mc = ModelCheckpoint('best_model.h5', monitor='val_loss', mode='min', save_best_only=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iHF522aVZ79L",
        "colab_type": "code",
        "outputId": "897eb7f9-a688-4a58-acd0-5a359bdaa21b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 431
        }
      },
      "cell_type": "code",
      "source": [
        "Conv = Sequential()\n",
        "\n",
        "Conv.add(Conv2D(32, kernel_size=3, padding='same', activation='relu', input_shape=(28, 28, 1)))\n",
        "Conv.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "Conv.add(Conv2D(64, kernel_size=3, padding='same', activation='relu'))\n",
        "Conv.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "Conv.add(Flatten())\n",
        "Conv.add(Dense(units=32, activation='relu'  ))\n",
        "Conv.add(Dropout(0.2))\n",
        "Conv.add(Dense(10, activation='softmax'))\n",
        "Conv.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "Conv.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_9 (Conv2D)            (None, 28, 28, 32)        320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_9 (MaxPooling2 (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 14, 14, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_10 (MaxPooling (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_5 (Flatten)          (None, 3136)              0         \n",
            "_________________________________________________________________\n",
            "dense_39 (Dense)             (None, 32)                100384    \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_40 (Dense)             (None, 10)                330       \n",
            "=================================================================\n",
            "Total params: 119,530\n",
            "Trainable params: 119,530\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "fW_VEnT8aDsR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_test = X_test.reshape(10000, 28, 28, 1)\n",
        "X_train = X_train.reshape(60000, 28, 28, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "W4dB7M0XbHmw",
        "colab_type": "code",
        "outputId": "9ff8767b-5a68-40b7-f9b3-4f7b3930588f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 413
        }
      },
      "cell_type": "code",
      "source": [
        "Conv.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=32)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 23s 382us/step - loss: 0.2454 - acc: 0.9237 - val_loss: 0.0574 - val_acc: 0.9820\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 19s 325us/step - loss: 0.0951 - acc: 0.9710 - val_loss: 0.0470 - val_acc: 0.9845\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 19s 324us/step - loss: 0.0700 - acc: 0.9794 - val_loss: 0.0383 - val_acc: 0.9872\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 20s 332us/step - loss: 0.0546 - acc: 0.9832 - val_loss: 0.0320 - val_acc: 0.9895\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 20s 332us/step - loss: 0.0444 - acc: 0.9864 - val_loss: 0.0284 - val_acc: 0.9903\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 20s 328us/step - loss: 0.0390 - acc: 0.9874 - val_loss: 0.0279 - val_acc: 0.9913\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 20s 335us/step - loss: 0.0327 - acc: 0.9895 - val_loss: 0.0348 - val_acc: 0.9899\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 20s 329us/step - loss: 0.0287 - acc: 0.9907 - val_loss: 0.0268 - val_acc: 0.9931\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 20s 331us/step - loss: 0.0271 - acc: 0.9914 - val_loss: 0.0365 - val_acc: 0.9897\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 19s 324us/step - loss: 0.0241 - acc: 0.9922 - val_loss: 0.0330 - val_acc: 0.9898\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fcffb244588>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "metadata": {
        "id": "wZTa1GW4cH-h",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.layers import BatchNormalization, Activation"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CD2vGCxnbRbo",
        "colab_type": "code",
        "outputId": "7a270e57-ebc1-48e3-eb00-61c288fbb6c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 575
        }
      },
      "cell_type": "code",
      "source": [
        "BN = Sequential()\n",
        "\n",
        "BN.add(Conv2D(32, kernel_size=3, padding='same', input_shape=(28, 28, 1)))\n",
        "BN.add(BatchNormalization())\n",
        "BN.add(Activation('relu'))\n",
        "BN.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "BN.add(Conv2D(64, kernel_size=3, padding='same'))\n",
        "BN.add(BatchNormalization())\n",
        "BN.add(Activation('relu'))\n",
        "BN.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "BN.add(Flatten())\n",
        "BN.add(Dense(units=32, activation='relu'  ))\n",
        "BN.add(Dropout(0.2))\n",
        "BN.add(Dense(10, activation='softmax'))\n",
        "BN.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "BN.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_12 (Conv2D)           (None, 28, 28, 32)        320       \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 28, 28, 32)        128       \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 28, 28, 32)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_11 (MaxPooling (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_13 (Conv2D)           (None, 14, 14, 64)        18496     \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 14, 14, 64)        256       \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_12 (MaxPooling (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_6 (Flatten)          (None, 3136)              0         \n",
            "_________________________________________________________________\n",
            "dense_41 (Dense)             (None, 32)                100384    \n",
            "_________________________________________________________________\n",
            "dropout_10 (Dropout)         (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_42 (Dense)             (None, 10)                330       \n",
            "=================================================================\n",
            "Total params: 119,914\n",
            "Trainable params: 119,722\n",
            "Non-trainable params: 192\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "p5WMWF4bc6ea",
        "colab_type": "code",
        "outputId": "356a5275-08bf-46a0-b1a9-eec2ae02a46c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 413
        }
      },
      "cell_type": "code",
      "source": [
        "BN.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=32)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 25s 425us/step - loss: 0.1323 - acc: 0.9558 - val_loss: 0.0395 - val_acc: 0.9882\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 26s 435us/step - loss: 0.1208 - acc: 0.9589 - val_loss: 0.0433 - val_acc: 0.9891\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 26s 434us/step - loss: 0.0984 - acc: 0.9673 - val_loss: 0.0360 - val_acc: 0.9898\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 26s 441us/step - loss: 0.0891 - acc: 0.9694 - val_loss: 0.0449 - val_acc: 0.9888\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 26s 435us/step - loss: 0.0871 - acc: 0.9710 - val_loss: 0.0387 - val_acc: 0.9897\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 26s 439us/step - loss: 0.0817 - acc: 0.9720 - val_loss: 0.0377 - val_acc: 0.9897\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 27s 443us/step - loss: 0.0685 - acc: 0.9771 - val_loss: 0.0344 - val_acc: 0.9919\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 27s 442us/step - loss: 0.0638 - acc: 0.9795 - val_loss: 0.0334 - val_acc: 0.9918\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 27s 446us/step - loss: 0.0606 - acc: 0.9800 - val_loss: 0.0456 - val_acc: 0.9886\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 26s 432us/step - loss: 0.0587 - acc: 0.9804 - val_loss: 0.0368 - val_acc: 0.9908\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fd0103ab940>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    }
  ]
}